{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from model_mnist import MLP, BinarizedMLP\n",
    "from model_torch_mnist import QuantizedMLP\n",
    "# from model_brevitas_mnist import BinarizedMLP\n",
    "from mnist_tools import train, test\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from math import floor\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"Adam\": optim.Adam,\n",
    "    \"AdaMax\": optim.Adamax,\n",
    "    \"AdaDelta\": optim.Adadelta\n",
    "}\n",
    "\n",
    "models = {\n",
    "    # \"Classic\": MLP,\n",
    "    # \"Binary\": BinarizedMLP,\n",
    "    'Quantized': QuantizedMLP\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {\"batch_size\": batch_size}\n",
    "test_kwargs = {\"batch_size\": batch_size}\n",
    "\n",
    "if device == \"cuda\":\n",
    "    cuda_kwargs = {\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"shuffle\": True\n",
    "        }\n",
    "\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "# Dataset configuration\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./mnist', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_kwargs)\n",
    "test_loader = DataLoader(test_dataset, **test_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.261208\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.727360\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.345264\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 3.204220\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 5.794360\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 6.614590\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 4.364017\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.540268\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.223597\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 3.123408\n",
      "\n",
      "Test set: Average loss: 370.8387, Accuracy: 8734/10000 (87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.341481\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.329241\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.292770\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.411379\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.766213\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.445190\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.271185\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.714928\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.466246\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.215759\n",
      "\n",
      "Test set: Average loss: 1040.3140, Accuracy: 8981/10000 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.483691\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.508588\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.253477\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.473302\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.424977\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.534574\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.399725\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.553972\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.433783\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.076038\n",
      "\n",
      "Test set: Average loss: 660.2466, Accuracy: 8597/10000 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.487782\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.291910\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.309252\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.272206\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.825764\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.428413\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.357554\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.645061\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.352723\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.885803\n",
      "\n",
      "Test set: Average loss: 335.8951, Accuracy: 8820/10000 (88%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.651026\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.351871\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.215994\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.201536\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.478319\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.285399\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.396221\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.218088\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.364957\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.703333\n",
      "\n",
      "Test set: Average loss: 341.8561, Accuracy: 9078/10000 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.272344\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.270770\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.211932\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.171509\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.328592\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.177290\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.305087\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.135474\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.256465\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.678567\n",
      "\n",
      "Test set: Average loss: 1216.6968, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.225326\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.251921\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.145030\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.113798\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.272977\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.169085\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.288904\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.197448\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.277568\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.552812\n",
      "\n",
      "Test set: Average loss: 534.9763, Accuracy: 9350/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.193553\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.192619\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.173198\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.104995\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.213189\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.189587\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.197932\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.221570\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.253322\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.442125\n",
      "\n",
      "Test set: Average loss: 0.4980, Accuracy: 9342/10000 (93%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.181026\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.183685\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.106363\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.094654\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.183918\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.188706\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.143257\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.186468\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.234393\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.363117\n",
      "\n",
      "Test set: Average loss: 12.5827, Accuracy: 9432/10000 (94%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.170545\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.157524\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.104200\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.090592\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.148296\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.176156\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.145324\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.186250\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.165856\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.312596\n",
      "\n",
      "Test set: Average loss: 220.3550, Accuracy: 9469/10000 (95%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.567871\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.787006\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.006255\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.562154\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.477698\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.648708\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.509153\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.529155\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.370799\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.863089\n",
      "\n",
      "Test set: Average loss: 1.9097, Accuracy: 8148/10000 (81%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.389484\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.283715\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.279697\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.321433\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.424641\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.500598\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.178897\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.523584\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.443213\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.990286\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 8580/10000 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.282673\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.397526\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.263613\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.346516\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.167192\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.327099\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.183738\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.449993\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.326522\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.628846\n",
      "\n",
      "Test set: Average loss: 0.7364, Accuracy: 9032/10000 (90%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.218579\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.281455\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.295008\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.214202\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.103414\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.295708\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.332245\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.645350\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.229304\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.394698\n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 8991/10000 (90%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.153003\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.262672\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.133876\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.169564\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.114840\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.343623\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.233879\n"
     ]
    }
   ],
   "source": [
    "from recorder import setup_logging\n",
    "from time import time\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    for optimizer_name, optimizer in optimizers.items():\n",
    "        \n",
    "        # Set up logging\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        log_filename = f\"{model_name}_{optimizer_name}_{timestamp}.txt\"\n",
    "        logger = setup_logging(log_filename, './log2/')\n",
    "               \n",
    "        model_instance = model_class().to(device)\n",
    "        optimizer = optimizer(model_instance.parameters(), lr=lr)\n",
    "        \n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=0.7) # default gamma by authors\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            start_train_time = time()\n",
    "            \n",
    "            train_loss, train_accuracy = train(False, model_instance, device, train_loader, optimizer, epoch, 100, logger)\n",
    "            train_time = time() - start_train_time\n",
    "\n",
    "            start_test_time = time()\n",
    "            test_loss, test_accuracy = test(model_instance, device, test_loader, logger)\n",
    "            test_time = time() - start_train_time\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "            results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"optimizer_name\": optimizer_name,\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_accuracy,\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_acc\": test_accuracy,\n",
    "                \"epoch_train_time\": train_time,\n",
    "                \"epoch_test_time\": test_time\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"mnist_experiments_results2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
