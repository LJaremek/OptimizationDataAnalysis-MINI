{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from model_svhn import ConvNetBinary, ConvNetClassic\n",
    "from cifar10_tools import train, test\n",
    "from datasets import SVHN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "\n",
    "dataset_class = SVHN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"Adam\": optim.Adam,\n",
    "    \"AdaMax\": optim.Adamax,\n",
    "    \"AdaDelta\": optim.Adadelta\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Classic_conv\": ConvNetClassic,\n",
    "    \"Binary_conv\": ConvNetBinary\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: svhn\\test_32x32.mat\n",
      "Using downloaded and verified file: svhn\\test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "train_kwargs = {\"batch_size\": batch_size}\n",
    "test_kwargs = {\"batch_size\": batch_size}\n",
    "\n",
    "if device == \"cuda\":\n",
    "    cuda_kwargs = {\n",
    "        \"num_workers\": 1,\n",
    "        \"pin_memory\": True,\n",
    "        \"shuffle\": True\n",
    "        }\n",
    "\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "train_dataset, test_dataset = dataset_class.get_train_and_test(\n",
    "    f\"./{dataset_class.name}\",\n",
    "    download=True\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Classic_conv, optimizer Adam (combination 1 out of 6)\n",
      "Start training epoch 1 of 10\n",
      "Finished training of epoch 1 in 461.1519365310669, staring testing\n",
      "epoch 1tested. test_acc: 89.34772587584511 test_loss: 0.0014833292380643903, epoch train time: 461.1519365310669\n",
      "estimated time left:  9h 59min 49s seconds\n",
      "Start training epoch 2 of 10\n",
      "Finished training of epoch 2 in 376.68506360054016, staring testing\n",
      "epoch 2tested. test_acc: 93.13537185003074 test_loss: 0.000979421987726634, epoch train time: 376.68506360054016\n",
      "estimated time left:  9h 10min 44s seconds\n",
      "Start training epoch 3 of 10\n",
      "Finished training of epoch 3 in 378.52149653434753, staring testing\n",
      "epoch 3tested. test_acc: 95.30577750460971 test_loss: 0.0007112509783954985, epoch train time: 378.52149653434753\n",
      "estimated time left:  8h 58min 27s seconds\n",
      "Start training epoch 4 of 10\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "i = 1\n",
    "nubmer_of_combinations = len(models) * len(optimizers)\n",
    "def estimate_time_left(time,number_of_calculation,all_calcualtions):\n",
    "    seconds = time/number_of_calculation*(all_calcualtions-number_of_calculation)\n",
    "    return f\" {int(seconds/3600)}h {int((seconds%3600)/60)}min {int(seconds%60)}s   \"\n",
    "\n",
    "all_start_train_time = time()\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    for optimizer_name, optimizer in optimizers.items():\n",
    "        print(f\"Model {model_name}, optimizer {optimizer_name} (combination {i} out of {nubmer_of_combinations})\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model_inctance = model_class().to(device)\n",
    "        optimizer = optimizer(model_inctance.parameters(), lr=lr)\n",
    "        for epoch in range(1, epochs+1):\n",
    "            print(f\"Start training epoch {epoch} of {epochs}\")\n",
    "            start_train_time = time()\n",
    "            train_loss, train_acc = train(\n",
    "                model_inctance, optimizer, criterion, train_loader, device, epoch\n",
    "            )\n",
    "            train_time = time() - start_train_time\n",
    "            print(f\"Finished training of epoch {epoch} in {train_time}, staring testing\")\n",
    "\n",
    "            start_test_time = time()\n",
    "            test_loss, test_acc = test(\n",
    "                model_inctance, criterion, test_loader, device\n",
    "                )\n",
    "            test_time = time() - start_train_time\n",
    "\n",
    "            print(f\"epoch {epoch}tested. test_acc: {test_acc} test_loss: {test_loss}, epoch train time: {train_time}\")\n",
    "            print(f\"estimated time left: {estimate_time_left(time() - all_start_train_time,(i-1)*epochs+epoch,epochs*nubmer_of_combinations)} seconds\")\n",
    "\n",
    "            results.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"optimizer_name\": optimizer_name,\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_acc\": test_acc,\n",
    "                \"epoch_train_time\": train_time,\n",
    "                \"epoch_test_time\": test_time\n",
    "            })\n",
    "        i = i+1\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(f\"{dataset_class.name}_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
